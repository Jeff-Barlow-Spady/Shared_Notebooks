{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install polars\n",
    "%pip install pandas_profiling\n",
    "%pip install pydantic\n",
    "import os\n",
    "import json\n",
    "import polars as pl \n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import geopandas as gpd\n",
    "from ydata_profiling import ProfileReport\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining file: Neighbourhoods_and_Wards_20231017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  11%|█         | 1/9 [00:00<00:01,  5.98it/s, Describe variable:Neighbourhood Number]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 17/17 [00:10<00:00,  1.62it/s, Completed]                                                   \n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.22s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 85.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspection complete.\n",
      "-----\n",
      "Examining file: Root_for_Trees_Inventory_20231022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 46/46 [00:14<00:00,  3.10it/s, Completed]                                         \n",
      "Generate report structure: 100%|██████████| 1/1 [00:12<00:00, 12.94s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspection complete.\n",
      "-----\n",
      "Examining file: Tree_Insects___Other_Pests_20231017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 22/22 [00:04<00:00,  5.39it/s, Completed]                                     \n",
      "Generate report structure: 100%|██████████| 1/1 [00:09<00:00,  9.41s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspection complete.\n",
      "-----\n",
      "Examining file: Vacant_Land_-_Industrial_20231017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 49/49 [00:14<00:00,  3.31it/s, Completed]                                         \n",
      "Generate report structure: 100%|██████████| 1/1 [00:12<00:00, 12.81s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspection complete.\n",
      "-----\n",
      "Inspection results saved to C:\\Users\\toast\\Downloads\\Climate_Data\\inspection_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Installs the Polars library for working with tabular data\n",
    "# Imports libraries for working with different data file types and generating data profiling reports\n",
    "# Loops through all files in the input directory\n",
    "# Determines file type and reads into appropriate DataFrame \n",
    "# Generates a ProfileReport for key info like data types, missing values\n",
    "# Extracts schema info, missing data stats, and other useful info\n",
    "# Saves results to a JSON file for later analysis\n",
    "#%pip install polars\n",
    "#%pip install pandas_profiling\n",
    "#%pip install pydantic\n",
    "#import os\n",
    "#import json\n",
    "#import polars as pl \n",
    "#import pandas as pd\n",
    "#import pandas_profiling\n",
    "#import geopandas as gpd\n",
    "#from ydata_profiling import ProfileReport\n",
    "#import numpy as np\n",
    "\n",
    "# Gather schema information\n",
    "inspection_results = []\n",
    "\n",
    "directory = r\"C:\\Users\\toast\\Downloads\\Climate_Data\\Tabular\\test\"\n",
    "output_folder = r\"C:\\Users\\toast\\Downloads\\Climate_Data\\Tabular\\test\\profiles\"\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith((\".csv\", \".xlsx\", \".geojson\", \".shp\")):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        print(f\"Examining file: {file}\")\n",
    "        \n",
    "        # Determine the file format and use appropriate library\n",
    "        if file.endswith((\".csv\", \".xlsx\")):\n",
    "            try:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    df = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                \n",
    "                # Generate a data profiling report\n",
    "                profile = ProfileReport(df)\n",
    "                # Save the profile report with the correct file extension\n",
    "                output_file_name = f\"profile_{os.path.splitext(file)[0]}.html\"  # Corrected the extension\n",
    "                profile.to_file(os.path.join(output_folder, output_file_name))\n",
    "                \n",
    "                # Gather schema information\n",
    "                schema_info = df.dtypes.to_dict()\n",
    "                \n",
    "                # Check for missing data\n",
    "                missing_data = df.isnull().sum().to_dict()\n",
    "                \n",
    "                # Extract useful information (customize as needed)\n",
    "                useful_info = {\n",
    "                    \"Total Rows\": len(df),\n",
    "                    \"Total Columns\": len(df.columns),\n",
    "                    \"Column Names\": df.columns.tolist(),\n",
    "                    \"Profile Report\": output_file_name                 ,\n",
    "                    \"Data Types\": schema_info,\n",
    "                    \"Missing Data\": missing_data,\n",
    "\n",
    "                    # Add more information as needed\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Handle any errors when reading the file\n",
    "                schema_info = {}\n",
    "                missing_data = {}\n",
    "                useful_info = {\"Error\": str(e)}\n",
    "        \n",
    "        elif file.endswith((\".geojson\", \".shp\")):\n",
    "            try:\n",
    "                if file.endswith(\".geojson\"):\n",
    "                    df = gpd.read_file(file_path)\n",
    "                else:\n",
    "                    df = gpd.read_file(file_path)\n",
    "                \n",
    "                # Gather schema information\n",
    "                schema_info = dict(df.dtypes)\n",
    "                \n",
    "                # Check for missing data\n",
    "                missing_data = df.isnull().sum().to_dict()\n",
    "                \n",
    "                # Extract useful information (customize as needed)\n",
    "                useful_info = {\n",
    "                    \"Total Rows\": len(df),\n",
    "                    \"Total Columns\": len(df.columns),\n",
    "                    \"Column Names\": df.columns.tolist(),\n",
    "                    \"Data Types\": schema_info,\n",
    "                    \"Missing Data\": missing_data,\n",
    "\n",
    "                    # Add more information as needed\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Handle any errors when reading the file\n",
    "                schema_info = {}\n",
    "                missing_data = {}\n",
    "                useful_info = {\"Error\": str(e)}\n",
    "        \n",
    "        # Store the inspection results in a dictionary\n",
    "        result = {\n",
    "            \"File Name\": file,\n",
    "            \"Missing Data\": missing_data,\n",
    "            \"Schema Info\": schema_info,\n",
    "            \"Useful Info\": useful_info,\n",
    "        }\n",
    "        \n",
    "        # Append the result to the list\n",
    "        inspection_results.append(result)\n",
    "        print(\"Inspection complete.\")\n",
    "        print(\"-----\")\n",
    "\n",
    "        # Save the profile report to disk\n",
    "        if \"Profile Report\" in useful_info:\n",
    "            profile_path = useful_info[\"Profile Report\"]\n",
    "            if os.path.exists(profile_path):\n",
    "                os.remove(profile_path)\n",
    "            if os.path.exists(f\"profile_{file}.html\"):\n",
    "                if os.path.exists(profile_path):\n",
    "                    os.remove(profile_path)\n",
    "                os.rename(f\"profile_{file}.html\", profile_path)\n",
    "\n",
    "# Save the inspection results to a JSON file\n",
    "output_file = r\"C:\\Users\\toast\\Downloads\\Climate_Data\\inspection_results.json\"\n",
    "\n",
    "def convert_dtype(obj):\n",
    "    if isinstance(obj, pd.Timestamp):\n",
    "        return obj.isoformat()\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(inspection_results, json_file, default=convert_dtype)\n",
    "\n",
    "print(f\"Inspection results saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(inspection_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(r\"C:\\Users\\toast\\Downloads\\Climate_Data\\inspection_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
